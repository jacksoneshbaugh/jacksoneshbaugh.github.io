---
layout: page
title: Recherche
permalink: /recherche/
page_id: research
lang: "fr"
---

<div style="font-size: 2rem; font-weight: 300; margin-bottom: 1rem;">
Je crois que l'une des plus grandes joies de la vie est de d√©couvrir et de construire de nouvelles choses, et de contribuer, m√™me modestement, au d√©bat scientifique.
</div>

<blockquote style="font-size: 1.1rem; margin-top: 1rem; font-style: italic;">
  Les actions du Seigneur sont extraordinaires, tous ceux qui les aiment r√©fl√©chissent sur elles ...<br>
  Il veut qu‚Äôon se souvienne de ses actions √©tonnantes. Le Seigneur a piti√©, il aime avec tendresse.
  <br>
  <span style="font-size: 0.95rem;">(Psaume 111:2,4, PDV2017)</span>
</blockquote>

# Int√©r√™ts de recherche

Je m'int√©resse √† l'interpr√©tabilit√© de l'apprentissage machine, √† la linguistique computationnelle et aux fondements
th√©oriques de l'intelligence artificielle. Je suis particuli√®rement int√©ress√© par des questions telles que: _Comment
rendre les r√©seaux neuronaux plus transparents ?_
et _Comment la structure linguistique et la s√©mantique interagissent-elles dans les mod√®les de traitement automatique du
langage naturel (TALN) multilingues ?_

<p style="margin-top: 1.5rem; font-size: 1rem;">
Vous pouvez consulter un r√©sum√© de mes projets de recherche et de mes publications scientifiques sur mon
<img alt="ORCID iD" src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png"
width="16" height="16" style="vertical-align: text-bottom; margin-left: 4px;" />
<a href="https://orcid.org/0009-0009-1806-2166" target="_blank" rel="noopener noreferrer" style="text-decoration: underline;">
profil ORCID</a>.
</p>

# Projets en cours

## Interpr√©tation des r√©seaux de neurones de r√©gression avec des substituts lin√©aires

**avril 2025‚ÄìAujourd'hui**

Dans ce projet, j'√©value la fiabilit√© des substituts lin√©aires pour l'interpr√©tation des r√©seaux de neurones. √Ä l'aide d'une m√©trique appel√©e score lambda, je mesure la capacit√© des mod√®les lin√©aires √† approximer les pr√©dictions et les repr√©sentations des r√©seaux entra√Æn√©s. Si les substituts atteignent souvent une forte corr√©lation, je montre que cela n'implique pas une approximation fid√®le¬†; en fait, la variance inexpliqu√©e restante peut correspondre √† la logique de d√©cision r√©elle du r√©seau. Cela sugg√®re que les substituts lin√©aires simples peuvent √™tre trompeurs, en particulier lorsque des comportements non lin√©aires cl√©s se situent dans des r√©gions √† faible variance de l'espace d'entr√©e.

√Ä l'avenir, je m'int√©resse au d√©veloppement d'un cadre connexe pour les t√¢ches de classification afin de d√©terminer si le d√©calage entre fid√©lit√© et pr√©cision observ√© en r√©gression se produit √©galement dans les contextes de classification. Je cherche √©galement √† caract√©riser plus pr√©cis√©ment l'√©cart fid√©lit√©-pr√©cision en √©tudiant la relation entre Œª(f) et le R¬≤ entre le substitut et la v√©rit√© terrain, en analysant quand et pourquoi une fid√©lit√© √©lev√©e du substitut ne parvient pas √† pr√©server les performances pr√©dictives.

### Publications  

**Jackson Eshbaugh.**  
*Fidelity Isn‚Äôt Accuracy: When Linearly Decodable Functions Fail to Match the Ground Truth.*  
arXiv preprint [arXiv:2506.12176](https://arxiv.org/abs/2506.12176), June 2025.  
üìÑ [PDF](https://arxiv.org/pdf/2506.12176)‚ÄÉüîó [arXiv](https://arxiv.org/abs/2506.12176)‚ÄÉüíª [Code](https://github.com/jacksoneshbaugh/lambda-linearity-score)

## D√©tection d'idiomes fran√ßais gr√¢ce aux techniques de traduction automatique neuronale

**f√©vrier 2025‚ÄìAujourd'hui**

Les expressions idiomatiques restent un d√©fi majeur en traduction automatique neuronale (NMT), entra√Ænant souvent des
erreurs dans les syst√®mes statistiques et modernes de NMT. ‚Äã‚ÄãDans ce projet, j'adapte des techniques efficaces pour
identifier les idiomes dans les corpus anglais et les applique aux donn√©es fran√ßaises. Ce travail, encore √† ses d√©buts,
constituera mon m√©moire de fin d'√©tudes en fran√ßais et en informatique.

## Am√©liorer la s√©curit√© √©nerg√©tique gr√¢ce aux r√©seaux neuronaux et aux arbres de d√©cision

**janvier 2025‚ÄìAujourd'hui**

La pr√©carit√© √©nerg√©tique est un r√©el probl√®me aux √âtats-Unis. Le gouvernement f√©d√©ral verse des fonds aux √âtats pour
lutter contre ce probl√®me. Cependant, les moyens de mobiliser ces fonds sont multiples, ce qui entra√Æne une r√©partition
inefficace. Nos travaux visent √† simplifier cette allocation en int√©grant les r√©seaux de neurones et les r√©seaux de
neurones profonds aux mod√®les √©nerg√©tiques des b√¢timents urbains (UBEM). Les r√©sultats de cette combinaison de mod√®les
permettront aux d√©cideurs politiques de visualiser les sch√©mas de consommation √©nerg√©tique, de comparer les strat√©gies
d'allocation des ressources et de simuler l'impact de diff√©rentes approches d'att√©nuation. Ce projet en est √† ses
d√©buts.

**En collaboration avec** le professeur Jorge Silveyra (Lafayette College)

# Projets √† venir

## FuncLearn: Un langage de programmation fonctionnel pour l'apprentissage machine

**Statut**: Conception pr√©liminaire

L'apprentissage machine est utilis√© dans de nombreuses disciplines, mais pour les personnes ext√©rieures √†
l'informatique, travailler avec Python et TensorFlow peut para√Ætre inutilement complexe. FuncLearn vise √† fournir un
langage fonctionnel simple, intuitif, proche de l'anglais, qui simplifie l'acc√®s. Ce langage compilera du code Python
bas√© sur TensorFlow, permettant aux utilisateurs d'importer des jeux de donn√©es, de cr√©er des mod√®les de cha√Æne et
d'entra√Æner des r√©seaux gr√¢ce √† une syntaxe expressive et composable ; aucune expertise en apprentissage machine n'est
requise.

# Int√©r√™ts / Id√©es √† long terme

Je m'int√©resse √©galement √† l'accessibilit√© des langages de programmation, en particulier au potentiel des mots-cl√©s
localis√©s (par exemple, en utilisant la syntaxe native comme `si` au lieu de `if`) et √† la refonte des structures
syntaxiques pour les langages s'√©crivant de droite √† gauche. Bien que ce travail soit encore conceptuel, il refl√®te un
int√©r√™t plus large pour la conception inclusive des langages.
